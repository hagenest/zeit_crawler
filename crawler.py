from bs4 import BeautifulSoup
# import re
import requests
import feedparser
import database as db


class Crawler:
    def __init__(self, feed, site):
        self.feed = feedparser.parse(feed)
        self.site = site

    # returns urls that arent't already in the database from given rss-feed
    def get_new_urls(self):
        urlList = []
        saved_urls = db.Article.select("url").get()
        for entry in self.feed.entries:
            if entry.link not in saved_urls:
                urlList.append(entry.link)
        return urlList

    def get_soup(self, url):
        content = requests.get(url).content
        soup = BeautifulSoup(content, "lxml")
        return soup

    def get_title(self, soup):
        return soup.title.string

    def get_summary(self, soup):
        return soup.find(name="description")

    def get_keywords(self, soup):
        keyword_list = []
        keywords = soup.find(name="keywords")
        print(keywords)
        return keywords.split(", ")

    def get_isPremium(self, soup):
        return "NULL"

    def get_authors(self, soup):
        authors = soup.find(name="author")
        return authors.split(", ")

    def insert_data(self, url):
        soup = self.get_soup(url)
        db.Article(
            url=url,
            title=self.get_title(soup),
            site=self.site,
            isPremium=self.get_isPremium(soup),
            summary=self.get_summary(soup),
        ).save()
        for keyword in self.get_keywords(soup):
            db.Keyword(url=url, keyword=self.get_keywords(soup)).save()
        for author in self.get_authors(soup):
            db.Author(url=url, author=self.get_authors(soup)).save()


class Zeit(Crawler):
    def get_isPremium(self, soup):
        if "Exklusiv f√ºr Abonnenten" in soup.prettify():
            return True
        else:
            return False
